strip.text=element_text(face="bold", size=18),
axis.line.x = element_line(color="black", size = 0.5),
axis.line.y = element_line(color="black", size = 0.5),
legend.position="top",
legend.key.size = unit(0.75, "cm"),
legend.text = element_text(size=18),
legend.key = element_rect(fill = "white")) +
#guides(color=guide_legend(nrow=1),)+
theme(axis.title.x = element_text(size=22, face="bold"),
axis.title.y= element_text(size=22, face="bold"))
png("figures/pub_figs/FigureS2.png", width=13, height=8, units="in", res=300)
fig5
dev.off()
pdf("figures/pub_figs/FigureS2a.pdf", width=13, height=8)
fig5
dev.off()
# Results script for the NEUS canopy_class paper
# Loading in data frames
# Loading in all of the base stuff we need
library(mgcv)
source("0_Calculate_GAMM_Posteriors_Updated.R") # This is a slightly updated version from what you were using earlier
source("0_Calculate_GAMM_Derivs.R")
# Setting up the base dataframe we need
new.dat <- read.csv("processed_data/sensitivity_extaction_dataframe.csv")
n <- 1000
predictors.all <- c("vpd.max", "tmean", "precip", "Species", "dbh.recon", "Canopy.Class", "spp.plot", "Site.Code", "Year", "PlotID", "spp.cc", "TreeID")
# ----------------------------------------
# Species level gam
# ----------------------------------------
load("processed_data/gam4_response_graph.Rdata")
load("processed_data/gam_results/gam4_species_only.Rdata")
# processed_data/gam_results/gam0_null_model_tempprecip.Rdata
spp.gam <- gam4; rm(gam4)
# spp.graph <- ci.terms.graph; rm(ci.terms.graph)
df.spp <- new.dat
vars.fac <- c("Site.Code", "PlotID", "TreeID", "Canopy.Class", "Species", "spp.cc")
var.smooth <- "Species"
for(v in vars.fac){
if(v %in% var.smooth) next # keep all levels for our "by" variable
# Get rid of unimportant levels for everything else
l1 <- unique(df.spp[,v])[1]
df.spp <- df.spp[df.spp[,v]==l1,]
}
summary(df.spp)
pred.spp <- c("tmean", "precip")
# spp.post <- post.distns(model.gam=spp.gam, newdata=df.spp, vars=pred.spp, terms=T)
# spp.post$x <- as.numeric(spp.post$x) # making x numeric; will make factors NA; NA's are ok here
# summary(spp.post)
spp.deriv <- calc.derivs(model.gam=spp.gam, newdata=df.spp, vars=pred.spp)
summary(spp.deriv)
data.use <- read.csv("processed_data/NESites_tree_plus_climate_and_BA.csv", header=T)
summary(data.use)
cc.tmean.data <- data.frame(Year = 1895:2015)
cc.precip.data <- data.frame(Year = 1895:2015)
cc.vpdmax.data <- data.frame(Year = 1895:2015)
for(i in unique(data.use$Site.Code)){
for(t in cc.tmean.data$Year){
if(length(which(data.use$Site.Code==i & data.use$Year==t))==0) next
cc.tmean.data[cc.tmean.data$Year==t,i] <- unique(data.use[data.use$Site.Code==i & data.use$Year==t , "tmean"])
cc.precip.data[cc.precip.data$Year==t,i] <- unique(data.use[data.use$Site.Code==i & data.use$Year==t, "precip"])
cc.vpdmax.data[cc.vpdmax.data$Year==t,i] <- unique(data.use[data.use$Site.Code==i & data.use$Year==t, "vpd.max"])
}
}
row.names(cc.tmean.data) <- cc.tmean.data$Year
cc.tmean.stack <- stack(cc.tmean.data[,!names(cc.tmean.data) %in% "Year"])
names(cc.tmean.stack) <- c("climate.var", "Site.Code")
cc.tmean.stack$type <- as.factor("Tmean")
cc.tmean.stack$Year <- as.numeric(row.names(cc.tmean.data))
summary(cc.tmean.stack)
row.names(cc.precip.data) <- cc.precip.data$Year
cc.precip.stack <- stack(cc.precip.data[,!names(cc.precip.data) %in% "Year"])
names(cc.precip.stack) <- c("climate.var", "Site.Code")
cc.precip.stack$type <- as.factor("Precip")
cc.precip.stack$Year <- as.numeric(row.names(cc.precip.data))
summary(cc.precip.stack)
row.names(cc.vpdmax.data) <- cc.vpdmax.data$Year
cc.vpdmax.stack <- stack(cc.vpdmax.data[,!names(cc.vpdmax.data) %in% "Year"])
names(cc.vpdmax.stack) <- c("climate.var", "Site.Code")
cc.vpdmax.stack$climate.var <- cc.vpdmax.stack$climate.var/100 # converting to kPa
cc.vpdmax.stack$type <- as.factor("VPDmax")
cc.vpdmax.stack$Year <- as.numeric(row.names(cc.tmean.data))
summary(cc.vpdmax.stack)
cc.climate.stack <- rbind(cc.tmean.stack, cc.precip.stack, cc.vpdmax.stack)
# sorting out sites so that they go from north at the top to south at the bottom
cc.climate.stack$Site.Code <- factor(cc.climate.stack$Site.Code, levels = c("HO", "GB", "RH", "GE", "PS", "NR", "HF", "LF"))
site.palette <- c("grey30", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
avg.climate <- data.frame(Site.Code = unique(cc.climate.stack$Site.Code),
Tmean = NA,
Precip = NA,
VPDmax = NA)
avg.climate
# Adding mean temperature line
for(i in unique(cc.climate.stack$Site.Code)){
avg.climate[avg.climate$Site==i, "Tmean"] <- mean(cc.climate.stack[cc.climate.stack$Site.Code==i & cc.climate.stack$type=="Tmean","climate.var"], na.rm=T)
avg.climate[avg.climate$Site==i, "Precip"] <- mean(cc.climate.stack[cc.climate.stack$Site.Code==i & cc.climate.stack$type=="Precip","climate.var"], na.rm=T)
avg.climate[avg.climate$Site==i, "VPDmax"] <- mean(cc.climate.stack[cc.climate.stack$Site.Code==i & cc.climate.stack$type=="VPDmax","climate.var"], na.rm=T)
}
avg.climate
avg.climate.stack <- stack(avg.climate)
names(avg.climate.stack) <- c("mean.values", "type")
avg.climate.stack$Site.Code <- avg.climate$Site.Code
fig2 <- ggplot(data=cc.climate.stack) + facet_grid(Site.Code~type, scales="free") +
geom_density(aes(x=climate.var, y = ..scaled.., fill=Site.Code, color=Site.Code), alpha=0.4) +
geom_vline(data= avg.climate.stack, aes(xintercept=mean.values, color=Site.Code)) +
scale_fill_manual(values=site.palette, guide = guide_legend(title = "Site")) +
scale_color_manual(values=site.palette, guide = guide_legend(title = "Site")) +
labs(x = expression(bold(paste("Temperature ("^"o", "C)"))), y = "Scaled") +
theme(axis.line=element_line(color="black"),
panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
panel.border=element_blank(),
panel.background=element_blank(),
axis.text.x=element_text(angle=0, color="black", size=16, vjust= 0.5),
axis.text.y=element_text(angle=0, color="black", size=16),
strip.text=element_text(face="bold", size=22),
axis.line.x = element_line(color="black", size = 0.5),
axis.line.y = element_line(color="black", size = 0.5),
legend.position="none") +
#legend.key.size = unit(0.75, "cm"),
#legend.text = element_text(size=22),
#legend.key = element_rect(fill = "white")) +
#guides(fill=guide_legend(nrow=1, title="")) +
theme(axis.title.y= element_text(size=24, face="bold")) +
theme(axis.title.x= element_text(size=24, face="bold"))
fig2
library(ggplot2)
fig2 <- ggplot(data=cc.climate.stack) + facet_grid(Site.Code~type, scales="free") +
geom_density(aes(x=climate.var, y = ..scaled.., fill=Site.Code, color=Site.Code), alpha=0.4) +
geom_vline(data= avg.climate.stack, aes(xintercept=mean.values, color=Site.Code)) +
scale_fill_manual(values=site.palette, guide = guide_legend(title = "Site")) +
scale_color_manual(values=site.palette, guide = guide_legend(title = "Site")) +
labs(x = expression(bold(paste("Temperature ("^"o", "C)"))), y = "Scaled") +
theme(axis.line=element_line(color="black"),
panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
panel.border=element_blank(),
panel.background=element_blank(),
axis.text.x=element_text(angle=0, color="black", size=16, vjust= 0.5),
axis.text.y=element_text(angle=0, color="black", size=16),
strip.text=element_text(face="bold", size=22),
axis.line.x = element_line(color="black", size = 0.5),
axis.line.y = element_line(color="black", size = 0.5),
legend.position="none") +
#legend.key.size = unit(0.75, "cm"),
#legend.text = element_text(size=22),
#legend.key = element_rect(fill = "white")) +
#guides(fill=guide_legend(nrow=1, title="")) +
theme(axis.title.y= element_text(size=24, face="bold")) +
theme(axis.title.x= element_text(size=24, face="bold"))
fig2
mean(cc.climate.stack[cc.climate.stack$type=="Tmean", "climate.var"], na.rm=T)
mean(cc.climate.stack[cc.climate.stack$type=="Precip", "climate.var"], na.rm=T)
load("processed_data/gam6_response_graph.Rdata")
ci.terms.graph$Canopy.Class <- recode(ci.terms.graph$Canopy.Class, "'I'='Intermediate'; 'U'='Understory'")
ci.terms.graph$Effect <- recode(ci.terms.graph$Effect, "'tmean'='Tmean';'precip'='Precip'")
ci.terms.graph$Effect <- factor(ci.terms.graph$Effect, levels= c("Tmean", "Precip", "dbh.recon"))
# DBH dwarfs Tmean and Precip
# will make 2 separate graphs and stitch together like ch2 of diss.
ci.terms.graph$Species <- factor(ci.terms.graph$Species, levels = c("TSCA", "FAGR", "ACRU", "QURU"))
library(car)
library(ggplot2)
load("processed_data/gam6_response_graph.Rdata")
ci.terms.graph$Canopy.Class <- recode(ci.terms.graph$Canopy.Class, "'I'='Intermediate'; 'U'='Understory'")
ci.terms.graph$Effect <- recode(ci.terms.graph$Effect, "'tmean'='Tmean';'precip'='Precip'")
ci.terms.graph$Effect <- factor(ci.terms.graph$Effect, levels= c("Tmean", "Precip", "dbh.recon"))
# DBH dwarfs Tmean and Precip
# will make 2 separate graphs and stitch together like ch2 of diss.
ci.terms.graph$Species <- factor(ci.terms.graph$Species, levels = c("TSCA", "FAGR", "ACRU", "QURU"))
summary(ci.terms.graph)
ci.terms.graph[ci.terms.graph$Effect=="Tmean" & ci.terms.graph$mean.bai=1, "x"]
ci.terms.graph[ci.terms.graph$Effect=="Tmean" & ci.terms.graph$mean.bai==1, "x"]
ci.terms.graph[ci.terms.graph$Effect=="Tmean" & ci.terms.graph$mean.bai==1 & !is.na(ci.terms.graph$Extent), "x"]
summary(ci.terms.graph[ci.terms.graph$Effect=="Tmean" & ci.terms.graph$mean.bai==1 & !is.na(ci.terms.graph$x), "x"])
summary(ci.terms.graph[ci.terms.graph$Effect=="Tmean" & ci.terms.graph$mean.bai==1 & !is.na(ci.terms.graph$x) & !is.na(ci.terms.graph$Effect), "x"])
summary(ci.terms.graph)
summary(ci.terms.graph[ci.terms.graph$Effect=="Tmean"  & !is.na(ci.terms.graph$x) & !is.na(ci.terms.graph$Effect), "x"])
ci.terms.graph[ci.terms.graph$Effect=="Tmean"  & !is.na(ci.terms.graph$Extent), "x"]
summary(ci.terms.graph[ci.terms.graph$Effect=="Tmean"  & !is.na(ci.terms.graph$x) & !is.na(ci.terms.graph$Effect), "x"])
# SKIP TO LINE 36 FOR DATA INPUT.
library(mgcv)
library(ggplot2)
library(car)
# Christy's GAMM code
# gam1 <- gamm(Y ~  s(Biomass, bs="cr", k=3, by=PFT) + s(tair, k=k, by=PFT) + s(precipf, k=k, by=PFT) + s(CO2, k=k, by=PFT), random=list(PlotID=~1), data=data)
# Loading in my data
# ne.data <- read.csv("processed_data/NESites_tree_plus_climate_and_BA.csv", header=T)
# ne.data$Live.Dead <- recode(ne.data$Live.Dead, "'Li'='LIVE'")
# summary(ne.data)
# ne.data2 <- ne.data[,c("Year", "Site.Code", "TreeID", "RW", "Species", "Canopy.Class", "Live.Dead", "DBH", "dbh.recon", "tmean", "precip", "BA", "BA.inc", "Plot")]
# names(ne.data2) <- c("Year", "Site.Code", "TreeID", "RW", "Species", "Canopy.Class", "Live.Dead", "DBH", "dbh.recon", "tmean", "precip", "BA", "BA.inc", "PlotID")
#
# phd.data <- read.csv("processed_data/AllSites_tree_plus_climate_and_BA.csv", header=T)
# summary(phd.data)
#
# ne.phd.data <- phd.data[phd.data$Site %in% c("Howland", "Harvard"),]
# ne.phd.data$DBH <- ne.phd.data$DBH..cm.
# ne.phd.data$Canopy.Class <- recode(ne.phd.data$Canopy.Class, "'S' = 'U'")
# ne.phd.data$Site.Code <- recode(ne.phd.data$Site, "'Howland'='HO';'Harvard'='HF'")
#
# ne.phd.data2 <- ne.phd.data[,c("Year", "Site.Code", "TreeID", "RW", "Species", "Canopy.Class", "Live.Dead", "DBH", "dbh.recon", "tmean", "precip", "BA", "BA.inc", "PlotID")]
#
# names(ne.data2)
# names(ne.phd.data2)
#
# data.use <- rbind(ne.data2, ne.phd.data2)
# summary(data.use)
# save(data.use, file="processed_data/gam_input_dataset.Rdata")
# Removing the huge BA.inc value tree.  I'm not sure what is happening there.  Ask Christy to take a look
# data.use <- data.use[!data.use$BA.inc > 140,]
# Loading in data.use
# Was merged in script #7 to facilitate VPD data
data.use <- read.csv("processed_data/NESites_tree_plus_climate_and_BA.csv", header=T)
# CR 4 Feb 2018 -- Rather than remove this value, lets just make it NA
# data.use[data.use$BA.inc > 140 & !is.na(data.use$BA.inc),]
data.use[!is.na(data.use$BA.inc) & data.use$BA.inc > 140, "BA.inc"] <- NA
summary(data.use)
# data.use$group <- data.use$Species
# data.use$group <- recode(data.use$group, "'CAOV' = 'CARYA'; 'CACO' = 'CARYA';
#                          'CATE' = 'CARYA'; 'ACSAC' = 'ACSA'; 'BEAL' = 'BETULA'; 'BELE' = 'BETULA'; 'QUMU' = 'QUAL'")
#
# data.use$group.plot <- as.factor(paste(data.use$group, data.use$PlotID, sep="."))
# data.use$Canopy.Class <- recode(data.use$Canopy.Class, "'C' = 'D'")
data.use$Canopy.Class <- recode(data.use$Canopy.Class, "'C' = 'Canopy'; 'D'='Canopy'")
# summary(data.use)
# trimming down the data used to be only living trees, and not any goofs or snags
data.use <- data.use[data.use$Live.Dead=="LIVE" & !is.na(data.use$Live.Dead) & !data.use$Canopy.Class=="F" & !is.na(data.use$Canopy.Class),]
summary(data.use)
# reducing the amount of data for the test runs
# sites.use <- c("Harvard", "Howland", "Morgan Monroe State Park", "Oak Openings Toledo", "Missouri Ozark")
# test <- data.use[data.use$Site %in% sites.use & !is.na(data.use$RW) & !is.na(data.use$BA.inc),]
test <- data.use[!is.na(data.use$RW) & !is.na(data.use$BA.inc),]
summary(test)
test$spp.cc <- as.factor(paste(test$Species, test$Canopy.Class, sep="."))
test$spp.plot <- as.factor(paste(test$Species, test$PlotID, sep="."))
summary(test)
# Get a list of what predictors & responses I'm using
predictors.all <- c("vpd.min", "vpd.max", "tmean", "precip", "Species", "dbh.recon", "Canopy.Class", "spp.plot", "Site.Code", "Year", "PlotID", "spp.cc")
# Getting rid of observations that have NAs in the important variables
test <- test[complete.cases(test[,predictors.all]),]
# test <- test[test$Live.Dead=="LIVE" & !test$Canopy.Class=="F",]
summary(test)
# Subsetting to a set of species that we have enough data to feel good about
#species.use <- c("TSCA", "QURU", "ACRU", "BEAL", "ACSA", "LITU", "QUAL", "CAOV", "CACO", "CATE", "JUVI", "QUVE", "PCRU", "THOC", "PIST")
# spp.use <- c("ACRU", "ACSA", "BETULA", "CARYA", "FAGR", "FRAX", "PIST", "QUAL", "QURU", "QUVE", "SAAL", "TSCA", "ULRU", "PCRU", "THOC", "LITU", "JUVI")
# Looking at select major species for these sites
spp.use <- c("TSCA", "ACRU", "QURU", "FAGR")
test <- test[test$Species %in% spp.use,]
summary(test)
# par(new=F)
# plot(test[test$TreeID=="MMA003", "BA.inc"]~ test[test$TreeID=="MMA003","Year"], type="l")
test$log.dbh <- log(test$dbh.recon)
summary(test)
summary(test)
summary(test$Live.Dead)
summary(test$Canopy.Class)
# RW <- test$RW
# temp <- test$tmean
# precip <- test$precip
# canopy <- test$Canopy.Class
# size <- test$DBH..cm.
# species <- unique(test$Species)
# library(ggplot2)
# ggplot(data=test) +
# facet_wrap(~PlotID) +
# geom_histogram(aes(x=dbh.recon))
# ggplot(data=test) +
# facet_wrap(~Species) +
# geom_histogram(aes(x=dbh.recon))
# hist(test$dbh.recon)
# test2 <- test[test$group %in% c("QURU", "ACRU") & test$Year>=1980,]
# test2 <- test[test$group %in% c("QURU", "ACRU"),]
# test2 <- test[test$Site %in% c("Morgan Monroe State Park", "Harvard"), ]
# test2$log.dbh <- log(test2$dbh.recon)
# summary(test2)
summary(test)
test[test$BA.inc==0, "BA.inc"] <- 1e-6
save(test, file="overstory_understory_combined_data_use.Rdata")
# test.gam3 <- test
# test.gam3$Canopy.Class <- recode(test.gam3$Canopy.Class, "'C' = 'Canopy'; 'D'='Canopy'")
# summary(test.gam3)
# Subsetting out just the FAGR (Gillbrook) and TSCA (Pisgah) for some site level runs
gb.fagr <- test[test$Site.Code %in%"GB" & test$Species %in% "FAGR",]
ps.tsca <- test[test$Site.Code %in%"PS" & test$Species %in% "TSCA",]
# Found a QURU from Lyford that was an outlier.  Understory tree that was 58cm DBH; Pulling that tree
test <- test[!test$TreeID %in% "LF2029",]
summary(test)
mean(test$tmean, na.rm=T)
load("processed_data/noaa_meta.Rdata")
summary(noaa.meta)
sites.neil <- read.csv("input_data/neil_ross_combo_update.csv", header=T)
summary(sites.neil)
fundiv.sites <- read.csv("input_data/FunDiv_european_sites.csv", header=T)
load("itrdb_europe.Rdata")
europe.itrdb <- itrdb.out
summary(europe.itrdb)
length(unique(noaa.meta$species.code))
length(unique(europe.itrdb$species.code))
us.itrdb.spp <- noaa.meta$species.code
combo.spp <- sites.neil$species
us.spp <- c(paste(us.itrdb.spp), paste(combo.spp))
unique.spp <- as.data.frame(as.factor(unique(us.spp)))
names(unique.spp) <- "Ross.postdoc.list"
names(unique.spp)
unique.spp
length(unique.spp)
nrow(unique.spp)
length(unique(noaa.meta$species.code))
length(unique(europe.itrdb$species.code))
summary(unique.spp)
## A slighly fancier map showing experimental & observational sites locations ##
# Christy Rollinson
# 25 July 2016
## housekeeping
rm(list=ls())
# Key libraries
library(ggplot2); library(maps)
# # library(rworldmap)
# Define our base directory
# Load in the locations for experimental and observational sites
load("processed_data/east_ITRDB.Rdata")
sites.ITRDB <- itrdb.metadata
#sites.obs <- read.csv("../obssiteinfo.csv")
summary(sites.ITRDB)
sites.ITRDB[,c("ITRDB.id", "lat", "lon")]
# Trimming to just the sites for ch. 2
#ch2.sites.exp <- sites.exp[sites.exp$site.name%in% c("Harvard Forest", "Howland Forest", "Morgan Monroe State Forest","Missouri Ozark","Ohio Oak Openings"),]
#ch2.sites.exp$state<- recode(ch2.sites.exp$site.name, "'Harvard Forest'='MA';'Howland Forest'='ME';'Morgan Monroe State Forest'='IN';'Missouri Ozark'='MO';'Ohio Oak Openings'='OH'")
#sites.obs[,c("Site.code", "Lat", "Long")]
#itrdb.map <- sites.exp[!sites.exp$site.name %in% c("Flagstaff control site", "Flagstaf managed forest", "Wind River Crane Site"),]
# -------------
# Note that in Sierra Nevadas, there appear to be two sites & these must be two separate rows
# -------------
# siernev <- sites.obs[sites.obs$Site.cod=="siernev", ]
# sn.lat <- as.numeric(strsplit(paste(siernev[, "Lat"]), split=",")[[1]])
# sn.lon <- as.numeric(strsplit(paste(siernev[, "Long"]), split=",")[[1]])
#
# cols <- 1:ncol(siernev)
# cols.excl <- which(names(siernev) %in% c("Lat", "Long"))
# cols[!cols %in% cols.excl]
# siernev <- siernev[,cols[!cols %in% cols.excl] ]
#
# siernev <- merge(siernev, data.frame(Lat=sn.lat, Long=sn.lon), all=T)
# siernev$Site.code <- c(paste0("siernev", 1:nrow(siernev)))
#
# # Merging sierra nevadas into the origin site.obs file
# #  -- Note: need to first drop siernev & then convert lat/lon to numeric
# sites.obs <- sites.obs[sites.obs$Site.code!="siernev", ]
# sites.obs$Lat <- as.numeric(paste(sites.obs$Lat))
# sites.obs$Long <- as.numeric(paste(sites.obs$Long))
# summary(sites.obs)
# sites.obs <- merge(sites.obs, siernev, all=T)
# summary(sites.obs)
# -------------
ch2.sites.exp[,c("site.name", "lat", "long")]
summary(ch2.sites.exp[,c("site.name", "lat", "long")])
#summary(sites.obs[,c("Site.code", "Lat", "Long")])
#sites.obs[,c("Site.code", "Site", "Lat", "Long")]
dat.map <- data.frame(Spp= c(paste(sites.ITRDB$species)),
Lat = c(sites.ITRDB$lat),
Lon = c(sites.ITRDB$lon),
ID = sites.ITRDB$ID,
type= c(rep("ITRDB", nrow(sites.ITRDB))))
summary(dat.map)
# Setting bounding box for mapping
lat.min <- 25.7617
lat.max <- 46.8640
lon.min <- -96.4003
lon.max <- -67.9980
library(raster)
# 10m land cover from Natural Earth http://www.naturalearthdata.com/downloads/10m-raster-data/10m-natural-earth-1/
nat.earth <- stack("~malexander10/Dropbox/Research/mapping_data/base_layers/NE1_HR_LC_SR_W_DR/NE1_HR_LC_SR_W_DR.tif")
# USFS forest cover http://www.mrlc.gov/nlcd11_data.php
#nat.earth <- stack("base_layers/CONUSCartographic_2_8_16/Cartographic/nlcd2011_usfs_conus_canopy_cartographic.img")
nat.crop <- crop(nat.earth, y=c(lon.min-5, lon.max+5, lat.min-5, lat.max+5))
nat.crop <- aggregate(nat.crop, fact=2, fun=mean)
rast.table <- data.frame(xyFromCell(nat.crop, 1:ncell(nat.crop)),
getValues(nat.crop/255))
rast.table$rgb <- with(rast.table, rgb(NE1_HR_LC_SR_W_DR.1,
NE1_HR_LC_SR_W_DR.2,
NE1_HR_LC_SR_W_DR.3,
1))
states <- map_data("state")
names(states)
summary(states)
names(states) <- c("Lon", "Lat", paste(names(states[,3:ncol(states)])))
# states.crop <- states[states$Lon %in% range(dat.map$Lon) & states$Lat %in% range(dat.map$Lat),]
dim(states)
# Note: the natural earth data takes quite a while to plot!`
# png("figures/ITRDB.png", width=10, height=5, units="in", res=220)
ggplot(data=dat.map) +
guides(fill="none") +
geom_tile(data=rast.table, aes(x=x, y=y), fill=rast.table$rgb) + # NOTE: fill MUST be outside of the aes otherwise it converts it to ggcolors
geom_path(data=states,aes(x = Lon, y = Lat, group=group), color = "black", size=0.1) +
geom_point(aes(x=Lon, y=Lat, color=type), size=2.5, alpha=0.75) +
#geom_text(data=ch2.sites.exp,aes(x=long+0.75, y=lat+0.75, label = paste("",as.character(state), sep="")), color="black", size=5,fontface="bold") +
scale_color_manual(values="red", name="Data Type") +
theme_bw() +
theme(legend.position="none") +
scale_x_continuous(expand=c(0,0), name="Degrees Longitude", limits =range(rast.table$x)) +
scale_y_continuous(expand=c(0,0), name="Degrees Latitude", limits=range(rast.table$y)) +
coord_equal()
dev.off()
#######################################################
# Making map of neil's expanded network
#######################################################
sites.neil <- read.csv("input_data/neil_ross_combo_update.csv")
summary(sites.neil)
# Removing the climate targeted sampling
sites.neil <- sites.neil[!sites.neil$Method %in% c("Targeted", "Climate", "Target"),]
unique(sites.neil$Method)
dat.map.neil <- data.frame(Spp= c(paste(sites.neil$species)),
Lat = c(sites.neil$LAT),
Lon = c(sites.neil$LONG),
type= c(rep("Expanded", nrow(sites.neil)))
)
summary(dat.map.neil)
ggplot(data=dat.map.neil) +
guides(fill="none") +
geom_tile(data=rast.table, aes(x=x, y=y), fill=rast.table$rgb) + # NOTE: fill MUST be outside of the aes otherwise it converts it to ggcolors
geom_path(data=states,aes(x = Lon, y = Lat, group=group), color = "black", size=0.1) +
geom_point(aes(x=Lon, y=Lat, color=type), size=2.5, alpha=0.75) +
#geom_text(data=ch2.sites.exp,aes(x=long+0.75, y=lat+0.75, label = paste("",as.character(state), sep="")), color="black", size=5,fontface="bold") +
scale_color_manual(values="red", name="Data Type") +
theme_bw() +
theme(legend.position="none") +
scale_x_continuous(expand=c(0,0), name="Degrees Longitude", limits =range(rast.table$x)) +
scale_y_continuous(expand=c(0,0), name="Degrees Latitude", limits=range(rast.table$y)) +
coord_equal()
# Combining maps together together
dat.map.all <- rbind(dat.map, dat.map.neil)
png("figures/grant_map.png", width=10, height=5, units="in", res=300)
ggplot(data=dat.map.all) +
guides(fill="none") +
geom_tile(data=rast.table, aes(x=x, y=y), fill=rast.table$rgb) + # NOTE: fill MUST be outside of the aes otherwise it converts it to ggcolors
geom_path(data=states,aes(x = Lon, y = Lat, group=group), color = "black", size=0.1) +
geom_point(aes(x=Lon, y=Lat, color=type), size=2.5, alpha=0.75) +
#geom_text(data=ch2.sites.exp,aes(x=long+0.75, y=lat+0.75, label = paste("",as.character(state), sep="")), color="black", size=5,fontface="bold") +
scale_color_manual(values= c("red", "blue"), name="Network") +
theme_bw() +
theme(legend.position="top") +
scale_x_continuous(expand=c(0,0), name="Degrees Longitude", limits =range(rast.table$x)) +
scale_y_continuous(expand=c(0,0), name="Degrees Latitude", limits=range(rast.table$y)) +
coord_equal()
dev.off()
################################
# Tryign to map the european sites
################################
library(ggplot2)
library(car)
require(plyr)
require(ggplot2)
require(RColorBrewer)
require(reshape)
require(scales)
require(zoo)
require(gridExtra)
require(grid)
load("itrdb_europe.Rdata")
# Setting bounding box for mapping
lat.min <- 34
lat.max <- 70
lon.min <- -9
lon.max <- 32
library(raster)
# 10m land cover from Natural Earth http://www.naturalearthdata.com/downloads/10m-raster-data/10m-natural-earth-1/
nat.earth <- stack("~malexander10/Dropbox/Research/mapping_data/base_layers/NE1_HR_LC_SR_W_DR/NE1_HR_LC_SR_W_DR.tif")
# USFS forest cover http://www.mrlc.gov/nlcd11_data.php
#nat.earth <- stack("base_layers/CONUSCartographic_2_8_16/Cartographic/nlcd2011_usfs_conus_canopy_cartographic.img")
nat.crop <- crop(nat.earth, y=c(lon.min-5, lon.max+5, lat.min-5, lat.max+5))
nat.crop <- aggregate(nat.crop, fact=2, fun=mean)
rast.table <- data.frame(xyFromCell(nat.crop, 1:ncell(nat.crop)),
getValues(nat.crop/255))
rast.table$rgb <- with(rast.table, rgb(NE1_HR_LC_SR_W_DR.1,
NE1_HR_LC_SR_W_DR.2,
NE1_HR_LC_SR_W_DR.3,
1))
worldmap2 <- map_data("world")
worldmap2$region <- as.factor(worldmap2$region)
europe.sites <- read.csv("input_data/FunDiv_coordinates_baeten2013.csv")
load("europe_outlines.Rdata")
summary(itrdb.out)
summary(europe.sites)
europe.sites$type <- as.factor("Expanded")
itrdb.out2 <- itrdb.out[,c("studyCode", "Latitude", "Longitude")]
names(itrdb.out2) <- c("site", "lat", "lon")
itrdb.out2$type <- as.factor("ITRDB")
europe.combo <- rbind(itrdb.out2,europe.sites)
europe.map <- ggplot(data=europe.combo) +
guides(fill="none") +
geom_tile(data=rast.table, aes(x=x, y=y), fill=rast.table$rgb) + # NOTE: fill MUST be outside of the aes otherwise it converts it to ggcolors
#geom_path(data=europe,aes(x = Lon, y = Lat, group=group), color = "black", size=0.1) +
geom_point(aes(x=lon, y=lat, color=type, size = type)) +
scale_color_manual(values = c("#E69F00","#0072B2"), guide = "legend", name="Network") +
scale_size_manual(values = c(1, 2.5)) +
guides(colour = guide_legend(override.aes = list(alpha = 1, size=4))) +
guides(size=F) +
#scale_color_manual(values="red", name="Data Type") +
theme_bw() +
theme(axis.title=element_blank(),
axis.text=element_blank(),
axis.ticks=element_blank(),
panel.grid.major=element_blank(),
panel.border=element_blank(),
panel.grid.minor=element_blank())+
theme(legend.position="none", legend.text= element_text(size=22),legend.title = element_text(size = 22, face = "bold")) +
coord_cartesian(xlim=range(europe.sites$lon), ylim=range(europe.sites$lat)) + coord_equal()+
scale_x_continuous(limits=range(europe.sites$lon, na.rm=T) + c(-2, 2),expand=c(0,0),name="Degrees Longitude")+
scale_y_continuous(limits=range(europe.sites$lat, na.rm=T) + c(-2,2), expand=c(0,0), name="Degrees Latitude")
europe.map
png("figures/grant_europe_map.png", height=5, width=5, units="in", res=300)
europe.map
dev.off()
